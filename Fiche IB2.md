pvalue > seuil : on accepte H0
pvalue < seuil : on rejette H0 (et donc on accepte H1)
- variables quantitatives (par exemple : la taille, le poids, ...)
- variables qualitatives (par exemple : la couleur des yeux, la
saison,...), avec un nombre fini de catÃ©gories (les modalitÃ©s) qui
peuvent Ãªtre ordonnÃ©es ou non

Deux (principaux) tests du XÂ² : QUALITATIF(S)
- Test du X2 d'adÃ©quation (1 variable)
- Test du X2 d'homogÃ©nÃ©itÃ© (2 variables)

Une table de contingence contient le nombre d'occurences de chaque
modalitÃ© d'une variable qualitative, ou de chaque couple de modalitÃ©s si on a 2 variables.
> table(variable1)
> table(variable1, variable2)

X2 adÃ©quation : 
> tab = table(sample)
> chisq.test(tab_sample,p=c(p1,p2,p3)) (ordre alphabÃ©tique)
H0 = la rÃ©partition des observations dans les diÃ©rents groupes est
conforme Ã  la rÃ©partition attendue

X2 homogÃ©nÃ©itÃ©/indÃ©
> tab = table(samp1,samp2), puis chisq.test(tab)
H0 = les critÃ¨res qualitatifs considÃ©rÃ©s sont indÃ©pendants

Shapiro = normal
Fisher = mÃªme variance
![[Pasted image 20230419120945.png]]

CorrÃ©lation : facteurs confusion A-> B et A -> C corr entre B et C
facteurs intermÃ©diaires : A -> B -> C corrÃ©lation A et C
hasard ; manip donnÃ©es

Tester normalitÃ© into test corrÃ©lation:
> cor.test(s1,s2, method = "pearson") normal
> cor.test(s1,s2, method = "spearman") pas normal
H0 = les Ã©chantillons ne sont pas corrÃ©lÃ©s

modÃ¨le linÃ©aires : reprÃ©sentation simplifiÃ©e de la rÃ©alitÃ©
Une variable expliquÃ©e (quantitative) et une/plusieurs variables explicatives quanti ou quali

mod = lm(y~x) ou lm(y~x1+x2)
test normalitÃ© des **rÃ©sidus** : shapiro.test(mod$residuals) 
summary(mod) et mod$coefficients pour avoir la rÃ©gression et les coeffs
a0 correspond Ã  la ligne (Intercept), a1 ligne x -> a0+a1x
plot(x,y) puis abline(mod)

si on veut comparer deux modÃ¨les il faut qu'ils soient emboitÃ©s et que leurs rÃ©sidus soient normaux

modÃ¨le sans facteur : > mod0 = lm(y ~ 1)
Comparaison modÃ¨les linÃ©aires:
H0 : "les modÃ¨les sont Ã©quivalents en terme de prÃ©diction"
- si on rejette l'hypothÃ¨se nulle, cela veut dire que l'un des modÃ¨les est meilleur pour expliquer les donnÃ©es : celui qui a le RSS le plus faible
- si on accepte l'hypothÃ¨se nulle, les modÃ¨les sont "similairement bons", on choisira donc le modÃ¨le le plus simple : celui qui a le moins de coefficients

> anova(mod1, mod2) 


si explicatif = qualitatif on pourra prÃ©dire une valeur pour chaque modalitÃ© de la variable qualitative
dans les coeffs : la prÃ©diction pour la modalitÃ© de rÃ©fÃ©rence (absent) correspond Ã  la ligne (Intercept)
la diffÃ©rence entre cette modalitÃ© et la deuxiÃ¨me correspond Ã  la ligne suivante... etc etc tt est comparÃ© Ã  la modalitÃ© de ref.

Si la pvalue est infÃ©rieure au seuil, le coefficient est significativement diffÃ©rent de 0 et il y a donc une diffÃ©rence par rapport Ã  la modalitÃ© de rÃ©fÃ©rence


Comparaison moyennes pour plus de 2 groupes.
boxplot(Taille ~ Antibiotique, data = donnees, main = "titre gnÃ©gnÃ©gnÃ©",xlab = "Concentration en antibiotique", ylab = "Taille des bactÃ©ries", col = rainbow(3))
- sÃ©parer tt les Ã©chantillons par modalitÃ©s dans des vecteurs
- vÃ©rifier leur normalitÃ© avec shapiro
- si tous normaux : bartlett.test(y~x)  H0=mÃªme variance
- si normalitÃ© et homodÃ©asticitÃ© : > aov(y~x) ; sinon kruskal.test(y~x)  H0 = mÃªme moyenne
mod= aov(y~x)
- si on trouve un effet et anova : TukeyHSD(mod), et faut voir pvalue inf Ã  alpha = diff signif. 


- si kruskal : test mann-whitney avec correction bonferroni (seuil alpha/nb comparaison) : wilcox.test(x1,y1). etc etc 
	si pval inf a alpha diff de moyenne
![[Pasted image 20230419123613.png]]

